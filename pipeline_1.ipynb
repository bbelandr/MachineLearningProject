{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ea1bb8d-6050-4760-8bae-5fa4fd8bf229",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "### Dataset Content Description\n",
    "- **timestamp** is the moment the question was given, represented as Unix timestamp in milliseconds.\n",
    "- **solving_id** represents each learning session of students corresponds to each bunle. It is a form of single\n",
    "integer, starting from 1 .\n",
    "- **question_id** is the ID of the question that given to student, which is a form of q{integer}.\n",
    "- **user_answer** is the answer that the student submitted, recorded as a character between a and d inclusively.\n",
    "- **elapsed_time** is the time that the students spends on each question in milliseconds.\n",
    "\n",
    "\n",
    "### Our Dataset\n",
    "We plan to reduce the data to have only columns for student_id, question_id, bundle_id, tags, elapsed_time, and correct\n",
    "- **student_id** is the ID of the student. We will not use this for training, but it's necessary for sorting so that we don't leak data\n",
    "- **bundle_id** is the bundle that a question is in. Bundles are sets of questions that reference the same passage/image/video/etc\n",
    "- **tags** are the skills associated with a certain question. Most question have multiple tags.\n",
    "- **Correct** is whether or not the student got the answer correct in that interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4991fd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import polars as pl # Using polars instead of pandas for speed. >9 million lines in 784k csv files.\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import pyarrow as pa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075b1155-faf3-4cdf-b8de-592f63e39f0f",
   "metadata": {},
   "source": [
    "#### Data Merging Preparation\n",
    "Our original dataset is comprised of one csv file per each of the 784k students, which results in massive overhead when reading in data. To prevent this, we're taking all of the relevant data and merging it into one unified dataset that can be easily read, navigated, and edited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bbf8e7-ccee-42a6-9e37-2760b4f6193c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kt1_dir = \"Data/KT1\"\n",
    "questions_fname = \"Data/contents/questions.csv\"\n",
    "\n",
    "# Load important columns of questions file (finding correct_answer and tags)\n",
    "# This only needs to be done once but we'll reference it multiple times per student interaction\n",
    "questions = (\n",
    "    pl.read_csv(questions_fname)\n",
    "    .with_columns([\n",
    "        pl.col(\"question_id\").str.replace(\"q\", \"\").cast(pl.Int32),\n",
    "        pl.col(\"bundle_id\").str.replace(\"b\", \"\").cast(pl.Int32),\n",
    "        pl.col(\"tags\").cast(pl.Utf8)\n",
    "    ])\n",
    "    .select([\"question_id\", \"correct_answer\", \"bundle_id\", \"tags\"])\n",
    ")\n",
    "\n",
    "\n",
    "student_files = [os.path.join(kt1_dir, f) for f in os.listdir(kt1_dir) if f.endswith(\".csv\")]\n",
    "\n",
    "dfs = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0608df86",
   "metadata": {},
   "source": [
    "### Data Fetching and Merging\n",
    "Here, we take all of the information that we need from each KT1 file and combine it into a single .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcc4fcd-f538-4ce5-ab06-1d83e8a42d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each interaction, we take the student_id, question_id, bundle_id, tags, elapsed_time, and whether they answered correctly\n",
    "for file in tqdm(student_files, desc=\"Progress\"):\n",
    "    # Take student_id from filename, remove 'u' prefix to make it int\n",
    "    student_id = int(os.path.basename(file).replace(\"u\", \"\").replace(\".csv\", \"\"))\n",
    "\n",
    "    df = (\n",
    "        pl.read_csv(file)\n",
    "        .with_columns([\n",
    "            pl.lit(student_id).alias(\"student_id\"),\n",
    "            pl.col(\"question_id\").str.replace(\"q\", \"\").cast(pl.Int32), # Remove 'q' prefix to make question_id int\n",
    "        ])\n",
    "        .join(questions, on=\"question_id\", how=\"left\")\n",
    "        .with_columns([\n",
    "            # Adds 'correct' column, which details if student got the question correct\n",
    "            (pl.col(\"user_answer\").str.strip_chars().str.to_lowercase() == pl.col(\"correct_answer\").str.strip_chars().str.to_lowercase())\n",
    "            .cast(pl.Int8)\n",
    "            .alias(\"correct\")\n",
    "        ])\n",
    "        .select([\"student_id\", \"question_id\", \"bundle_id\", \"tags\", \"elapsed_time\", \"correct\"])\n",
    "    )\n",
    "\n",
    "    # Tags are currently in a list, we need to flatten them so they work in csv\n",
    "    df = df.with_columns(\n",
    "        pl.col(\"tags\")\n",
    "        .cast(pl.Utf8)\n",
    "        .str.replace_all(r\"\\[|\\]|\\s\", \"\")\n",
    "        .str.replace_all(\",\", \";\")\n",
    "        .alias(\"tags\")\n",
    "    )\n",
    "\n",
    "    dfs.append(df)\n",
    "\n",
    "# Sort by student_id, then question_id\n",
    "final_df = pl.concat(dfs, how=\"vertical\").sort([\"student_id\", \"question_id\"])\n",
    "\n",
    "fname = \"combined_dataset.csv\"\n",
    "final_df.write_csv(fname)\n",
    "print(f\"Saved {fname}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdf7949",
   "metadata": {},
   "source": [
    "### Model 1 Baseline Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6aa557ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall student accuracy: 65.3418%\n"
     ]
    }
   ],
   "source": [
    "data = pl.read_csv(rf\".\\Data\\combined_dataset.csv\")\n",
    "df = data.to_pandas() # Convert from polars to pandas\n",
    "\n",
    "correct_count = df['correct'].value_counts()\n",
    "student_acc = correct_count.get(1) / (correct_count.get(0) + correct_count.get(1))\n",
    "print(f\"Overall student accuracy: {student_acc:.4%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7905732",
   "metadata": {},
   "source": [
    "Our baseline accuracy to compare against is 65.3418%, which is what we would get if the model guessed that the student will be 'correct' every time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
